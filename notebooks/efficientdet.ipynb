{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-06T11:29:19.166045300Z",
     "start_time": "2024-01-06T11:28:44.002928900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.saved_model.load('../models/efficientdet_d1_coco17_tpu-32/saved_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resize if necessary\n",
    "    # image = cv2.resize(image, (desired_width, desired_height))\n",
    "\n",
    "    # Convert to uint8\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.uint8)\n",
    "\n",
    "    # Add batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "image = load_and_preprocess_image('latest.jpg')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T12:48:16.236197Z",
     "start_time": "2024-01-06T12:48:16.194004400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "detections = model(image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T12:48:18.224610100Z",
     "start_time": "2024-01-06T12:48:17.269524400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "class_names = {}\n",
    "with open('../models/coco_labels.txt', 'r') as file:\n",
    "    for i, line in enumerate(file.readlines(), start=1):\n",
    "        class_names[i] = line.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T12:48:19.142223800Z",
     "start_time": "2024-01-06T12:48:19.134586600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "# Extract bounding boxes from the model's output\n",
    "boxes = detections['detection_boxes'].numpy()\n",
    "classes = detections['detection_classes'].numpy()\n",
    "scores = detections['detection_scores'].numpy()\n",
    "\n",
    "# Load the original image\n",
    "original_image = cv2.imread('latest.jpg')\n",
    "\n",
    "# Make sure the image was loaded correctly\n",
    "if original_image is None:\n",
    "    raise ValueError(\"Image not found or path is incorrect\")\n",
    "\n",
    "# Original image dimensions\n",
    "height, width, _ = original_image.shape  # original_image is your original image\n",
    "\n",
    "for i in range(boxes.shape[1]):\n",
    "    if scores[0, i] > 0.5:  # Score threshold\n",
    "        box = boxes[0, i]\n",
    "        class_id = int(classes[0, i])\n",
    "\n",
    "        # Scale box to original image dimensions\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "        xmin = int(xmin * width)\n",
    "        xmax = int(xmax * width)\n",
    "        ymin = int(ymin * height)\n",
    "        ymax = int(ymax * height)\n",
    "\n",
    "        # Draw the bounding box\n",
    "        cv2.rectangle(original_image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "        # Draw label\n",
    "        label = f'{class_names.get(class_id, \"N/A\")} : {int(scores[0, i] * 100)}%'\n",
    "        cv2.putText(original_image, label, (xmin, ymin-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T12:48:20.864467Z",
     "start_time": "2024-01-06T12:48:20.814331300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "cv2.imshow('Object Detection', original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T12:48:25.448168200Z",
     "start_time": "2024-01-06T12:48:21.982381Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered detections: 6\n",
      "[{'xmin': 262, 'ymin': 335, 'xmax': 516, 'ymax': 443}, {'xmin': 267, 'ymin': 128, 'xmax': 502, 'ymax': 243}, {'xmin': 238, 'ymin': 532, 'xmax': 507, 'ymax': 661}, {'xmin': 833, 'ymin': 561, 'xmax': 1104, 'ymax': 686}, {'xmin': 821, 'ymin': 328, 'xmax': 1071, 'ymax': 448}, {'xmin': 810, 'ymin': 146, 'xmax': 1038, 'ymax': 253}]\n"
     ]
    }
   ],
   "source": [
    "detected_objects = []\n",
    "\n",
    "for i in range(boxes.shape[1]):\n",
    "    score = scores[0, i]\n",
    "    if score > 0.5:\n",
    "        class_id = int(classes[0, i])\n",
    "        label = class_names.get(class_id, \"N/A\")\n",
    "        if label in ['2  car', '86  scissors']:\n",
    "            ymin, xmin, ymax, xmax = boxes[0, i]\n",
    "            xmin = int(xmin * width)\n",
    "            xmax = int(xmax * width)\n",
    "            ymin = int(ymin * height)\n",
    "            ymax = int(ymax * height)\n",
    "\n",
    "            detected_object = {\n",
    "                'xmin': xmin,\n",
    "                'ymin': ymin,\n",
    "                'xmax': xmax,\n",
    "                'ymax': ymax\n",
    "            }\n",
    "\n",
    "            # Add the object to the list\n",
    "            detected_objects.append(detected_object)\n",
    "\n",
    "\n",
    "print(f\"Filtered detections: {len(detected_objects)}\")\n",
    "print(detected_objects)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T13:04:59.955331Z",
     "start_time": "2024-01-06T13:04:59.941446900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T12:49:20.809731100Z",
     "start_time": "2024-01-06T12:49:20.787477Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
